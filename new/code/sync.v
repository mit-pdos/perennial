(* autogenerated from sync *)
Require Export New.code.internal.race.
Require Export New.code.sync.atomic.

From New.golang Require Import defn.core.
From New.golang.defn Require Export slice array map string interface defer builtin.
Require Export New.trusted_code.sync.
Import sync.
Definition sync : go_string := "sync".

Module sync.

Module Cond. Definition id : go_string := "sync.Cond"%go. End Cond.
Module copyChecker. Definition id : go_string := "sync.copyChecker"%go. End copyChecker.
Module noCopy. Definition id : go_string := "sync.noCopy"%go. End noCopy.
Module Map. Definition id : go_string := "sync.Map"%go. End Map.
Module readOnly. Definition id : go_string := "sync.readOnly"%go. End readOnly.
Module entry. Definition id : go_string := "sync.entry"%go. End entry.
Module Mutex. Definition id : go_string := "sync.Mutex"%go. End Mutex.
Module Locker. Definition id : go_string := "sync.Locker"%go. End Locker.
Module Once. Definition id : go_string := "sync.Once"%go. End Once.
Module Pool. Definition id : go_string := "sync.Pool"%go. End Pool.
Module poolLocalInternal. Definition id : go_string := "sync.poolLocalInternal"%go. End poolLocalInternal.
Module poolLocal. Definition id : go_string := "sync.poolLocal"%go. End poolLocal.
Module poolDequeue. Definition id : go_string := "sync.poolDequeue"%go. End poolDequeue.
Module eface. Definition id : go_string := "sync.eface"%go. End eface.
Module dequeueNil. Definition id : go_string := "sync.dequeueNil"%go. End dequeueNil.
Module poolChain. Definition id : go_string := "sync.poolChain"%go. End poolChain.
Module poolChainElt. Definition id : go_string := "sync.poolChainElt"%go. End poolChainElt.
Module notifyList. Definition id : go_string := "sync.notifyList"%go. End notifyList.
Module RWMutex. Definition id : go_string := "sync.RWMutex"%go. End RWMutex.
Module rlocker. Definition id : go_string := "sync.rlocker"%go. End rlocker.
Module WaitGroup. Definition id : go_string := "sync.WaitGroup"%go. End WaitGroup.

Section code.
Context `{ffi_syntax}.


Definition noCopy : go_type := structT [
].
#[global] Typeclasses Opaque noCopy.
#[global] Opaque noCopy.

Definition Locker : go_type := interfaceT.
#[global] Typeclasses Opaque Locker.
#[global] Opaque Locker.

Axiom notifyList : go_type.

Axiom copyChecker : go_type.

Definition Cond : go_type := structT [
  "noCopy" :: noCopy;
  "L" :: Locker;
  "notify" :: notifyList;
  "checker" :: copyChecker
].
#[global] Typeclasses Opaque Cond.
#[global] Opaque Cond.

Definition NewCond : go_string := "sync.NewCond"%go.

(* NewCond returns a new Cond with Locker l.

   go: cond.go:48:6 *)
Definition NewCondⁱᵐᵖˡ : val :=
  λ: "l",
    exception_do (let: "l" := (mem.alloc "l") in
    return: (mem.alloc (let: "$L" := (![#Locker] "l") in
     struct.make #Cond [{
       "noCopy" ::= type.zero_val #noCopy;
       "L" ::= "$L";
       "notify" ::= type.zero_val #notifyList;
       "checker" ::= type.zero_val #copyChecker
     }]))).

Definition runtime_notifyListWait : go_string := "sync.runtime_notifyListWait"%go.

Definition runtime_notifyListAdd : go_string := "sync.runtime_notifyListAdd"%go.

(* Wait atomically unlocks c.L and suspends execution
   of the calling goroutine. After later resuming execution,
   Wait locks c.L before returning. Unlike in other systems,
   Wait cannot return unless awoken by [Cond.Broadcast] or [Cond.Signal].

   Because c.L is not locked while Wait is waiting, the caller
   typically cannot assume that the condition is true when
   Wait returns. Instead, the caller should Wait in a loop:

   	c.L.Lock()
   	for !condition() {
   	    c.Wait()
   	}
   	... make use of condition ...
   	c.L.Unlock()

   go: cond.go:67:16 *)
Definition Cond__Waitⁱᵐᵖˡ : val :=
  λ: "c" <>,
    exception_do (let: "c" := (mem.alloc "c") in
    do:  ((method_call #(ptrT.id copyChecker.id) #"check"%go (struct.field_ref #Cond #"checker"%go (![#ptrT] "c"))) #());;;
    let: "t" := (mem.alloc (type.zero_val #uint32T)) in
    let: "$r0" := (let: "$a0" := (struct.field_ref #Cond #"notify"%go (![#ptrT] "c")) in
    (func_call #runtime_notifyListAdd) "$a0") in
    do:  ("t" <-[#uint32T] "$r0");;;
    do:  ((interface.get #"Unlock"%go (![#Locker] (struct.field_ref #Cond #"L"%go (![#ptrT] "c")))) #());;;
    do:  (let: "$a0" := (struct.field_ref #Cond #"notify"%go (![#ptrT] "c")) in
    let: "$a1" := (![#uint32T] "t") in
    (func_call #runtime_notifyListWait) "$a0" "$a1");;;
    do:  ((interface.get #"Lock"%go (![#Locker] (struct.field_ref #Cond #"L"%go (![#ptrT] "c")))) #());;;
    return: #()).

Definition runtime_notifyListNotifyOne : go_string := "sync.runtime_notifyListNotifyOne"%go.

(* Signal wakes one goroutine waiting on c, if there is any.

   It is allowed but not required for the caller to hold c.L
   during the call.

   Signal() does not affect goroutine scheduling priority; if other goroutines
   are attempting to lock c.L, they may be awoken before a "waiting" goroutine.

   go: cond.go:82:16 *)
Definition Cond__Signalⁱᵐᵖˡ : val :=
  λ: "c" <>,
    exception_do (let: "c" := (mem.alloc "c") in
    do:  ((method_call #(ptrT.id copyChecker.id) #"check"%go (struct.field_ref #Cond #"checker"%go (![#ptrT] "c"))) #());;;
    do:  (let: "$a0" := (struct.field_ref #Cond #"notify"%go (![#ptrT] "c")) in
    (func_call #runtime_notifyListNotifyOne) "$a0");;;
    return: #()).

Definition runtime_notifyListNotifyAll : go_string := "sync.runtime_notifyListNotifyAll"%go.

(* Broadcast wakes all goroutines waiting on c.

   It is allowed but not required for the caller to hold c.L
   during the call.

   go: cond.go:91:16 *)
Definition Cond__Broadcastⁱᵐᵖˡ : val :=
  λ: "c" <>,
    exception_do (let: "c" := (mem.alloc "c") in
    do:  ((method_call #(ptrT.id copyChecker.id) #"check"%go (struct.field_ref #Cond #"checker"%go (![#ptrT] "c"))) #());;;
    do:  (let: "$a0" := (struct.field_ref #Cond #"notify"%go (![#ptrT] "c")) in
    (func_call #runtime_notifyListNotifyAll) "$a0");;;
    return: #()).

Axiom Map : go_type.

Axiom readOnly : go_type.

Definition expunged : go_string := "sync.expunged"%go.

Axiom expunged'init : val.

Axiom entry : go_type.

Definition newEntry : go_string := "sync.newEntry"%go.

Definition Once : go_type := structT [
  "_0" :: noCopy;
  "done" :: atomic.Uint32;
  "m" :: Mutex
].
#[global] Typeclasses Opaque Once.
#[global] Opaque Once.

(* Do calls the function f if and only if Do is being called for the
   first time for this instance of [Once]. In other words, given

   	var once Once

   if once.Do(f) is called multiple times, only the first call will invoke f,
   even if f has a different value in each invocation. A new instance of
   Once is required for each function to execute.

   Do is intended for initialization that must be run exactly once. Since f
   is niladic, it may be necessary to use a function literal to capture the
   arguments to a function to be invoked by Do:

   	config.once.Do(func() { config.init(filename) })

   Because no call to Do returns until the one call to f returns, if f causes
   Do to be called, it will deadlock.

   If f panics, Do considers it to have returned; future calls of Do return
   without calling f.

   go: once.go:52:16 *)
Definition Once__Doⁱᵐᵖˡ : val :=
  λ: "o" "f",
    exception_do (let: "o" := (mem.alloc "o") in
    let: "f" := (mem.alloc "f") in
    (if: ((method_call #(ptrT.id atomic.Uint32.id) #"Load"%go (struct.field_ref #Once #"done"%go (![#ptrT] "o"))) #()) = #(W32 0)
    then
      do:  (let: "$a0" := (![#funcT] "f") in
      (method_call #(ptrT.id Once.id) #"doSlow"%go (![#ptrT] "o")) "$a0")
    else do:  #());;;
    return: #()).

(* go: once.go:73:16 *)
Definition Once__doSlowⁱᵐᵖˡ : val :=
  λ: "o" "f",
    with_defer: (let: "o" := (mem.alloc "o") in
    let: "f" := (mem.alloc "f") in
    do:  ((method_call #(ptrT.id Mutex.id) #"Lock"%go (struct.field_ref #Once #"m"%go (![#ptrT] "o"))) #());;;
    do:  (let: "$f" := (method_call #(ptrT.id Mutex.id) #"Unlock"%go (struct.field_ref #Once #"m"%go (![#ptrT] "o"))) in
    "$defer" <-[#funcT] (let: "$oldf" := (![#funcT] "$defer") in
    (λ: <>,
      "$f" #();;
      "$oldf" #()
      )));;;
    (if: ((method_call #(ptrT.id atomic.Uint32.id) #"Load"%go (struct.field_ref #Once #"done"%go (![#ptrT] "o"))) #()) = #(W32 0)
    then
      do:  (let: "$a0" := #(W32 1) in
      let: "$f" := (method_call #(ptrT.id atomic.Uint32.id) #"Store"%go (struct.field_ref #Once #"done"%go (![#ptrT] "o"))) in
      "$defer" <-[#funcT] (let: "$oldf" := (![#funcT] "$defer") in
      (λ: <>,
        "$f" "$a0";;
        "$oldf" #()
        )));;;
      do:  ((![#funcT] "f") #())
    else do:  #());;;
    return: #()).

Definition OnceFunc : go_string := "sync.OnceFunc"%go.

Definition OnceValue : go_string := "sync.OnceValue"%go.

Definition OnceValues : go_string := "sync.OnceValues"%go.

Axiom Pool : go_type.

Axiom poolLocalInternal : go_type.

Axiom poolLocal : go_type.

Definition runtime_randn : go_string := "sync.runtime_randn"%go.

Definition poolRaceHash : go_string := "sync.poolRaceHash"%go.

Definition poolRaceAddr : go_string := "sync.poolRaceAddr"%go.

Definition poolCleanup : go_string := "sync.poolCleanup"%go.

Definition allPoolsMu : go_string := "sync.allPoolsMu"%go.

Definition allPools : go_string := "sync.allPools"%go.

Definition oldPools : go_string := "sync.oldPools"%go.

Definition init : go_string := "sync.init"%go.

Definition indexLocal : go_string := "sync.indexLocal"%go.

Definition runtime_registerPoolCleanup : go_string := "sync.runtime_registerPoolCleanup"%go.

Definition runtime_procPin : go_string := "sync.runtime_procPin"%go.

Definition runtime_procUnpin : go_string := "sync.runtime_procUnpin"%go.

Definition runtime_LoadAcquintptr : go_string := "sync.runtime_LoadAcquintptr"%go.

Definition runtime_StoreReluintptr : go_string := "sync.runtime_StoreReluintptr"%go.

Axiom poolDequeue : go_type.

Axiom eface : go_type.

Axiom dequeueBits : Z.

Axiom dequeueLimit : Z.

Axiom dequeueNil : go_type.

Axiom poolChain : go_type.

Axiom poolChainElt : go_type.

Definition runtime_Semacquire : go_string := "sync.runtime_Semacquire"%go.

Definition runtime_SemacquireWaitGroup : go_string := "sync.runtime_SemacquireWaitGroup"%go.

Definition runtime_SemacquireRWMutexR : go_string := "sync.runtime_SemacquireRWMutexR"%go.

Definition runtime_SemacquireRWMutex : go_string := "sync.runtime_SemacquireRWMutex"%go.

Definition runtime_Semrelease : go_string := "sync.runtime_Semrelease"%go.

Definition runtime_notifyListCheck : go_string := "sync.runtime_notifyListCheck"%go.

Definition throw : go_string := "sync.throw"%go.

Definition fatal : go_string := "sync.fatal"%go.

Definition RWMutex : go_type := structT [
  "w" :: Mutex;
  "writerSem" :: uint32T;
  "readerSem" :: uint32T;
  "readerCount" :: atomic.Int32;
  "readerWait" :: atomic.Int32
].
#[global] Typeclasses Opaque RWMutex.
#[global] Opaque RWMutex.

Definition rwmutexMaxReaders : Z := 1073741824.

(* RLock locks rw for reading.

   It should not be used for recursive read locking; a blocked Lock
   call excludes new readers from acquiring the lock. See the
   documentation on the [RWMutex] type.

   go: rwmutex.go:67:20 *)
Definition RWMutex__RLockⁱᵐᵖˡ : val :=
  λ: "rw" <>,
    exception_do (let: "rw" := (mem.alloc "rw") in
    (if: race.Enabled
    then
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"w"%go (![#ptrT] "rw")) in
      (func_call #race.Read) "$a0");;;
      do:  ((func_call #race.Disable) #())
    else do:  #());;;
    (if: int_lt (let: "$a0" := #(W32 1) in
    (method_call #(ptrT.id atomic.Int32.id) #"Add"%go (struct.field_ref #RWMutex #"readerCount"%go (![#ptrT] "rw"))) "$a0") #(W32 0)
    then
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"readerSem"%go (![#ptrT] "rw")) in
      let: "$a1" := #false in
      let: "$a2" := #(W64 0) in
      (func_call #runtime_SemacquireRWMutexR) "$a0" "$a1" "$a2")
    else do:  #());;;
    (if: race.Enabled
    then
      do:  ((func_call #race.Enable) #());;;
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"readerSem"%go (![#ptrT] "rw")) in
      (func_call #race.Acquire) "$a0")
    else do:  #());;;
    return: #()).

(* TryRLock tries to lock rw for reading and reports whether it succeeded.

   Note that while correct uses of TryRLock do exist, they are rare,
   and use of TryRLock is often a sign of a deeper problem
   in a particular use of mutexes.

   go: rwmutex.go:87:20 *)
Definition RWMutex__TryRLockⁱᵐᵖˡ : val :=
  λ: "rw" <>,
    exception_do (let: "rw" := (mem.alloc "rw") in
    (if: race.Enabled
    then
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"w"%go (![#ptrT] "rw")) in
      (func_call #race.Read) "$a0");;;
      do:  ((func_call #race.Disable) #())
    else do:  #());;;
    (for: (λ: <>, #true); (λ: <>, #()) := λ: <>,
      let: "c" := (mem.alloc (type.zero_val #int32T)) in
      let: "$r0" := ((method_call #(ptrT.id atomic.Int32.id) #"Load"%go (struct.field_ref #RWMutex #"readerCount"%go (![#ptrT] "rw"))) #()) in
      do:  ("c" <-[#int32T] "$r0");;;
      (if: int_lt (![#int32T] "c") #(W32 0)
      then
        (if: race.Enabled
        then do:  ((func_call #race.Enable) #())
        else do:  #());;;
        return: (#false)
      else do:  #());;;
      (if: let: "$a0" := (![#int32T] "c") in
      let: "$a1" := ((![#int32T] "c") + #(W32 1)) in
      (method_call #(ptrT.id atomic.Int32.id) #"CompareAndSwap"%go (struct.field_ref #RWMutex #"readerCount"%go (![#ptrT] "rw"))) "$a0" "$a1"
      then
        (if: race.Enabled
        then
          do:  ((func_call #race.Enable) #());;;
          do:  (let: "$a0" := (struct.field_ref #RWMutex #"readerSem"%go (![#ptrT] "rw")) in
          (func_call #race.Acquire) "$a0")
        else do:  #());;;
        return: (#true)
      else do:  #()))).

(* RUnlock undoes a single [RWMutex.RLock] call;
   it does not affect other simultaneous readers.
   It is a run-time error if rw is not locked for reading
   on entry to RUnlock.

   go: rwmutex.go:114:20 *)
Definition RWMutex__RUnlockⁱᵐᵖˡ : val :=
  λ: "rw" <>,
    exception_do (let: "rw" := (mem.alloc "rw") in
    (if: race.Enabled
    then
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"w"%go (![#ptrT] "rw")) in
      (func_call #race.Read) "$a0");;;
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"writerSem"%go (![#ptrT] "rw")) in
      (func_call #race.ReleaseMerge) "$a0");;;
      do:  ((func_call #race.Disable) #())
    else do:  #());;;
    (let: "r" := (mem.alloc (type.zero_val #int32T)) in
    let: "$r0" := (let: "$a0" := #(W32 (- 1)) in
    (method_call #(ptrT.id atomic.Int32.id) #"Add"%go (struct.field_ref #RWMutex #"readerCount"%go (![#ptrT] "rw"))) "$a0") in
    do:  ("r" <-[#int32T] "$r0");;;
    (if: int_lt (![#int32T] "r") #(W32 0)
    then
      do:  (let: "$a0" := (![#int32T] "r") in
      (method_call #(ptrT.id RWMutex.id) #"rUnlockSlow"%go (![#ptrT] "rw")) "$a0")
    else do:  #()));;;
    (if: race.Enabled
    then do:  ((func_call #race.Enable) #())
    else do:  #());;;
    return: #()).

(* go: rwmutex.go:129:20 *)
Definition RWMutex__rUnlockSlowⁱᵐᵖˡ : val :=
  λ: "rw" "r",
    exception_do (let: "rw" := (mem.alloc "rw") in
    let: "r" := (mem.alloc "r") in
    (if: (((![#int32T] "r") + #(W32 1)) = #(W32 0)) || (((![#int32T] "r") + #(W32 1)) = #(W32 (- rwmutexMaxReaders)))
    then
      do:  ((func_call #race.Enable) #());;;
      do:  (let: "$a0" := #"sync: RUnlock of unlocked RWMutex"%go in
      (func_call #fatal) "$a0")
    else do:  #());;;
    (if: (let: "$a0" := #(W32 (- 1)) in
    (method_call #(ptrT.id atomic.Int32.id) #"Add"%go (struct.field_ref #RWMutex #"readerWait"%go (![#ptrT] "rw"))) "$a0") = #(W32 0)
    then
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"writerSem"%go (![#ptrT] "rw")) in
      let: "$a1" := #false in
      let: "$a2" := #(W64 1) in
      (func_call #runtime_Semrelease) "$a0" "$a1" "$a2")
    else do:  #());;;
    return: #()).

(* Lock locks rw for writing.
   If the lock is already locked for reading or writing,
   Lock blocks until the lock is available.

   go: rwmutex.go:144:20 *)
Definition RWMutex__Lockⁱᵐᵖˡ : val :=
  λ: "rw" <>,
    exception_do (let: "rw" := (mem.alloc "rw") in
    (if: race.Enabled
    then
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"w"%go (![#ptrT] "rw")) in
      (func_call #race.Read) "$a0");;;
      do:  ((func_call #race.Disable) #())
    else do:  #());;;
    do:  ((method_call #(ptrT.id Mutex.id) #"Lock"%go (struct.field_ref #RWMutex #"w"%go (![#ptrT] "rw"))) #());;;
    let: "r" := (mem.alloc (type.zero_val #int32T)) in
    let: "$r0" := ((let: "$a0" := #(W32 (- rwmutexMaxReaders)) in
    (method_call #(ptrT.id atomic.Int32.id) #"Add"%go (struct.field_ref #RWMutex #"readerCount"%go (![#ptrT] "rw"))) "$a0") + #(W32 rwmutexMaxReaders)) in
    do:  ("r" <-[#int32T] "$r0");;;
    (if: ((![#int32T] "r") ≠ #(W32 0)) && ((let: "$a0" := (![#int32T] "r") in
    (method_call #(ptrT.id atomic.Int32.id) #"Add"%go (struct.field_ref #RWMutex #"readerWait"%go (![#ptrT] "rw"))) "$a0") ≠ #(W32 0))
    then
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"writerSem"%go (![#ptrT] "rw")) in
      let: "$a1" := #false in
      let: "$a2" := #(W64 0) in
      (func_call #runtime_SemacquireRWMutex) "$a0" "$a1" "$a2")
    else do:  #());;;
    (if: race.Enabled
    then
      do:  ((func_call #race.Enable) #());;;
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"readerSem"%go (![#ptrT] "rw")) in
      (func_call #race.Acquire) "$a0");;;
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"writerSem"%go (![#ptrT] "rw")) in
      (func_call #race.Acquire) "$a0")
    else do:  #());;;
    return: #()).

(* TryLock tries to lock rw for writing and reports whether it succeeded.

   Note that while correct uses of TryLock do exist, they are rare,
   and use of TryLock is often a sign of a deeper problem
   in a particular use of mutexes.

   go: rwmutex.go:169:20 *)
Definition RWMutex__TryLockⁱᵐᵖˡ : val :=
  λ: "rw" <>,
    exception_do (let: "rw" := (mem.alloc "rw") in
    (if: race.Enabled
    then
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"w"%go (![#ptrT] "rw")) in
      (func_call #race.Read) "$a0");;;
      do:  ((func_call #race.Disable) #())
    else do:  #());;;
    (if: (~ ((method_call #(ptrT.id Mutex.id) #"TryLock"%go (struct.field_ref #RWMutex #"w"%go (![#ptrT] "rw"))) #()))
    then
      (if: race.Enabled
      then do:  ((func_call #race.Enable) #())
      else do:  #());;;
      return: (#false)
    else do:  #());;;
    (if: (~ (let: "$a0" := #(W32 0) in
    let: "$a1" := #(W32 (- rwmutexMaxReaders)) in
    (method_call #(ptrT.id atomic.Int32.id) #"CompareAndSwap"%go (struct.field_ref #RWMutex #"readerCount"%go (![#ptrT] "rw"))) "$a0" "$a1"))
    then
      do:  ((method_call #(ptrT.id Mutex.id) #"Unlock"%go (struct.field_ref #RWMutex #"w"%go (![#ptrT] "rw"))) #());;;
      (if: race.Enabled
      then do:  ((func_call #race.Enable) #())
      else do:  #());;;
      return: (#false)
    else do:  #());;;
    (if: race.Enabled
    then
      do:  ((func_call #race.Enable) #());;;
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"readerSem"%go (![#ptrT] "rw")) in
      (func_call #race.Acquire) "$a0");;;
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"writerSem"%go (![#ptrT] "rw")) in
      (func_call #race.Acquire) "$a0")
    else do:  #());;;
    return: (#true)).

(* Unlock unlocks rw for writing. It is a run-time error if rw is
   not locked for writing on entry to Unlock.

   As with Mutexes, a locked [RWMutex] is not associated with a particular
   goroutine. One goroutine may [RWMutex.RLock] ([RWMutex.Lock]) a RWMutex and then
   arrange for another goroutine to [RWMutex.RUnlock] ([RWMutex.Unlock]) it.

   go: rwmutex.go:201:20 *)
Definition RWMutex__Unlockⁱᵐᵖˡ : val :=
  λ: "rw" <>,
    exception_do (let: "rw" := (mem.alloc "rw") in
    (if: race.Enabled
    then
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"w"%go (![#ptrT] "rw")) in
      (func_call #race.Read) "$a0");;;
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"readerSem"%go (![#ptrT] "rw")) in
      (func_call #race.Release) "$a0");;;
      do:  ((func_call #race.Disable) #())
    else do:  #());;;
    let: "r" := (mem.alloc (type.zero_val #int32T)) in
    let: "$r0" := (let: "$a0" := #(W32 rwmutexMaxReaders) in
    (method_call #(ptrT.id atomic.Int32.id) #"Add"%go (struct.field_ref #RWMutex #"readerCount"%go (![#ptrT] "rw"))) "$a0") in
    do:  ("r" <-[#int32T] "$r0");;;
    (if: int_geq (![#int32T] "r") #(W32 rwmutexMaxReaders)
    then
      do:  ((func_call #race.Enable) #());;;
      do:  (let: "$a0" := #"sync: Unlock of unlocked RWMutex"%go in
      (func_call #fatal) "$a0")
    else do:  #());;;
    (let: "i" := (mem.alloc (type.zero_val #intT)) in
    let: "$r0" := #(W64 0) in
    do:  ("i" <-[#intT] "$r0");;;
    (for: (λ: <>, int_lt (![#intT] "i") (s_to_w64 (![#int32T] "r"))); (λ: <>, do:  ("i" <-[#intT] ((![#intT] "i") + #(W64 1)))) := λ: <>,
      do:  (let: "$a0" := (struct.field_ref #RWMutex #"readerSem"%go (![#ptrT] "rw")) in
      let: "$a1" := #false in
      let: "$a2" := #(W64 0) in
      (func_call #runtime_Semrelease) "$a0" "$a1" "$a2")));;;
    do:  ((method_call #(ptrT.id Mutex.id) #"Unlock"%go (struct.field_ref #RWMutex #"w"%go (![#ptrT] "rw"))) #());;;
    (if: race.Enabled
    then do:  ((func_call #race.Enable) #())
    else do:  #());;;
    return: #()).

Definition syscall_hasWaitingReaders : go_string := "sync.syscall_hasWaitingReaders"%go.

(* RLocker returns a [Locker] interface that implements
   the [Locker.Lock] and [Locker.Unlock] methods by calling rw.RLock and rw.RUnlock.

   go: rwmutex.go:240:20 *)
Definition RWMutex__RLockerⁱᵐᵖˡ : val :=
  λ: "rw" <>,
    exception_do (let: "rw" := (mem.alloc "rw") in
    return: (interface.make #(ptrT.id rlocker.id) (![#ptrT] "rw"))).

Definition rlocker : go_type := RWMutex.
#[global] Typeclasses Opaque rlocker.
#[global] Opaque rlocker.

Definition WaitGroup : go_type := structT [
  "noCopy" :: noCopy;
  "state" :: atomic.Uint64;
  "sema" :: uint32T
].
#[global] Typeclasses Opaque WaitGroup.
#[global] Opaque WaitGroup.

(* Add adds delta, which may be negative, to the [WaitGroup] counter.
   If the counter becomes zero, all goroutines blocked on [WaitGroup.Wait] are released.
   If the counter goes negative, Add panics.

   Note that calls with a positive delta that occur when the counter is zero
   must happen before a Wait. Calls with a negative delta, or calls with a
   positive delta that start when the counter is greater than zero, may happen
   at any time.
   Typically this means the calls to Add should execute before the statement
   creating the goroutine or other event to be waited for.
   If a WaitGroup is reused to wait for several independent sets of events,
   new Add calls must happen after all previous Wait calls have returned.
   See the WaitGroup example.

   go: waitgroup.go:45:22 *)
Definition WaitGroup__Addⁱᵐᵖˡ : val :=
  λ: "wg" "delta",
    with_defer: (let: "wg" := (mem.alloc "wg") in
    let: "delta" := (mem.alloc "delta") in
    (if: race.Enabled
    then
      (if: int_lt (![#intT] "delta") #(W64 0)
      then
        do:  (let: "$a0" := (![#ptrT] "wg") in
        (func_call #race.ReleaseMerge) "$a0")
      else do:  #());;;
      do:  ((func_call #race.Disable) #());;;
      do:  (let: "$f" := (func_call #race.Enable) in
      "$defer" <-[#funcT] (let: "$oldf" := (![#funcT] "$defer") in
      (λ: <>,
        "$f" #();;
        "$oldf" #()
        )))
    else do:  #());;;
    let: "state" := (mem.alloc (type.zero_val #uint64T)) in
    let: "$r0" := (let: "$a0" := ((s_to_w64 (![#intT] "delta")) ≪ #(W64 32)) in
    (method_call #(ptrT.id atomic.Uint64.id) #"Add"%go (struct.field_ref #WaitGroup #"state"%go (![#ptrT] "wg"))) "$a0") in
    do:  ("state" <-[#uint64T] "$r0");;;
    let: "v" := (mem.alloc (type.zero_val #int32T)) in
    let: "$r0" := (u_to_w32 ((![#uint64T] "state") ≫ #(W64 32))) in
    do:  ("v" <-[#int32T] "$r0");;;
    let: "w" := (mem.alloc (type.zero_val #uint32T)) in
    let: "$r0" := (u_to_w32 (![#uint64T] "state")) in
    do:  ("w" <-[#uint32T] "$r0");;;
    (if: (race.Enabled && (int_gt (![#intT] "delta") #(W64 0))) && ((![#int32T] "v") = (s_to_w32 (![#intT] "delta")))
    then
      do:  (let: "$a0" := (struct.field_ref #WaitGroup #"sema"%go (![#ptrT] "wg")) in
      (func_call #race.Read) "$a0")
    else do:  #());;;
    (if: int_lt (![#int32T] "v") #(W32 0)
    then
      do:  (let: "$a0" := (interface.make #stringT.id #"sync: negative WaitGroup counter"%go) in
      Panic "$a0")
    else do:  #());;;
    (if: (((![#uint32T] "w") ≠ #(W32 0)) && (int_gt (![#intT] "delta") #(W64 0))) && ((![#int32T] "v") = (s_to_w32 (![#intT] "delta")))
    then
      do:  (let: "$a0" := (interface.make #stringT.id #"sync: WaitGroup misuse: Add called concurrently with Wait"%go) in
      Panic "$a0")
    else do:  #());;;
    (if: (int_gt (![#int32T] "v") #(W32 0)) || ((![#uint32T] "w") = #(W32 0))
    then return: (#())
    else do:  #());;;
    (if: ((method_call #(ptrT.id atomic.Uint64.id) #"Load"%go (struct.field_ref #WaitGroup #"state"%go (![#ptrT] "wg"))) #()) ≠ (![#uint64T] "state")
    then
      do:  (let: "$a0" := (interface.make #stringT.id #"sync: WaitGroup misuse: Add called concurrently with Wait"%go) in
      Panic "$a0")
    else do:  #());;;
    do:  (let: "$a0" := #(W64 0) in
    (method_call #(ptrT.id atomic.Uint64.id) #"Store"%go (struct.field_ref #WaitGroup #"state"%go (![#ptrT] "wg"))) "$a0");;;
    (for: (λ: <>, (![#uint32T] "w") ≠ #(W32 0)); (λ: <>, do:  ("w" <-[#uint32T] ((![#uint32T] "w") - #(W32 1)))) := λ: <>,
      do:  (let: "$a0" := (struct.field_ref #WaitGroup #"sema"%go (![#ptrT] "wg")) in
      let: "$a1" := #false in
      let: "$a2" := #(W64 0) in
      (func_call #runtime_Semrelease) "$a0" "$a1" "$a2"));;;
    return: #()).

(* Done decrements the [WaitGroup] counter by one.

   go: waitgroup.go:88:22 *)
Definition WaitGroup__Doneⁱᵐᵖˡ : val :=
  λ: "wg" <>,
    exception_do (let: "wg" := (mem.alloc "wg") in
    do:  (let: "$a0" := #(W64 (- 1)) in
    (method_call #(ptrT.id WaitGroup.id) #"Add"%go (![#ptrT] "wg")) "$a0");;;
    return: #()).

(* Wait blocks until the [WaitGroup] counter is zero.

   go: waitgroup.go:93:22 *)
Definition WaitGroup__Waitⁱᵐᵖˡ : val :=
  λ: "wg" <>,
    exception_do (let: "wg" := (mem.alloc "wg") in
    (if: race.Enabled
    then do:  ((func_call #race.Disable) #())
    else do:  #());;;
    (for: (λ: <>, #true); (λ: <>, #()) := λ: <>,
      let: "state" := (mem.alloc (type.zero_val #uint64T)) in
      let: "$r0" := ((method_call #(ptrT.id atomic.Uint64.id) #"Load"%go (struct.field_ref #WaitGroup #"state"%go (![#ptrT] "wg"))) #()) in
      do:  ("state" <-[#uint64T] "$r0");;;
      let: "v" := (mem.alloc (type.zero_val #int32T)) in
      let: "$r0" := (u_to_w32 ((![#uint64T] "state") ≫ #(W64 32))) in
      do:  ("v" <-[#int32T] "$r0");;;
      let: "w" := (mem.alloc (type.zero_val #uint32T)) in
      let: "$r0" := (u_to_w32 (![#uint64T] "state")) in
      do:  ("w" <-[#uint32T] "$r0");;;
      (if: (![#int32T] "v") = #(W32 0)
      then
        (if: race.Enabled
        then
          do:  ((func_call #race.Enable) #());;;
          do:  (let: "$a0" := (![#ptrT] "wg") in
          (func_call #race.Acquire) "$a0")
        else do:  #());;;
        return: (#())
      else do:  #());;;
      (if: let: "$a0" := (![#uint64T] "state") in
      let: "$a1" := ((![#uint64T] "state") + #(W64 1)) in
      (method_call #(ptrT.id atomic.Uint64.id) #"CompareAndSwap"%go (struct.field_ref #WaitGroup #"state"%go (![#ptrT] "wg"))) "$a0" "$a1"
      then
        (if: race.Enabled && ((![#uint32T] "w") = #(W32 0))
        then
          do:  (let: "$a0" := (struct.field_ref #WaitGroup #"sema"%go (![#ptrT] "wg")) in
          (func_call #race.Write) "$a0")
        else do:  #());;;
        do:  (let: "$a0" := (struct.field_ref #WaitGroup #"sema"%go (![#ptrT] "wg")) in
        (func_call #runtime_SemacquireWaitGroup) "$a0");;;
        (if: ((method_call #(ptrT.id atomic.Uint64.id) #"Load"%go (struct.field_ref #WaitGroup #"state"%go (![#ptrT] "wg"))) #()) ≠ #(W64 0)
        then
          do:  (let: "$a0" := (interface.make #stringT.id #"sync: WaitGroup is reused before previous Wait has returned"%go) in
          Panic "$a0")
        else do:  #());;;
        (if: race.Enabled
        then
          do:  ((func_call #race.Enable) #());;;
          do:  (let: "$a0" := (![#ptrT] "wg") in
          (func_call #race.Acquire) "$a0")
        else do:  #());;;
        return: (#())
      else do:  #()));;;
    return: #()).

Definition vars' : list (go_string * go_type) := [].

Axiom newEntryⁱᵐᵖˡ : val.

Axiom OnceFuncⁱᵐᵖˡ : val.

Axiom OnceValueⁱᵐᵖˡ : val.

Axiom OnceValuesⁱᵐᵖˡ : val.

Axiom runtime_randnⁱᵐᵖˡ : val.

Axiom poolRaceAddrⁱᵐᵖˡ : val.

Axiom poolCleanupⁱᵐᵖˡ : val.

Axiom indexLocalⁱᵐᵖˡ : val.

Axiom runtime_registerPoolCleanupⁱᵐᵖˡ : val.

Axiom runtime_procPinⁱᵐᵖˡ : val.

Axiom runtime_procUnpinⁱᵐᵖˡ : val.

Axiom runtime_LoadAcquintptrⁱᵐᵖˡ : val.

Axiom runtime_StoreReluintptrⁱᵐᵖˡ : val.

Axiom throwⁱᵐᵖˡ : val.

Axiom fatalⁱᵐᵖˡ : val.

Axiom syscall_hasWaitingReadersⁱᵐᵖˡ : val.

Definition functions' : list (go_string * val) := [(NewCond, NewCondⁱᵐᵖˡ); (newEntry, newEntryⁱᵐᵖˡ); (OnceFunc, OnceFuncⁱᵐᵖˡ); (OnceValue, OnceValueⁱᵐᵖˡ); (OnceValues, OnceValuesⁱᵐᵖˡ); (runtime_randn, runtime_randnⁱᵐᵖˡ); (poolRaceAddr, poolRaceAddrⁱᵐᵖˡ); (poolCleanup, poolCleanupⁱᵐᵖˡ); (indexLocal, indexLocalⁱᵐᵖˡ); (runtime_registerPoolCleanup, runtime_registerPoolCleanupⁱᵐᵖˡ); (runtime_procPin, runtime_procPinⁱᵐᵖˡ); (runtime_procUnpin, runtime_procUnpinⁱᵐᵖˡ); (runtime_LoadAcquintptr, runtime_LoadAcquintptrⁱᵐᵖˡ); (runtime_StoreReluintptr, runtime_StoreReluintptrⁱᵐᵖˡ); (runtime_Semacquire, runtime_Semacquireⁱᵐᵖˡ); (runtime_SemacquireWaitGroup, runtime_SemacquireWaitGroupⁱᵐᵖˡ); (runtime_SemacquireRWMutexR, runtime_SemacquireRWMutexRⁱᵐᵖˡ); (runtime_SemacquireRWMutex, runtime_SemacquireRWMutexⁱᵐᵖˡ); (runtime_Semrelease, runtime_Semreleaseⁱᵐᵖˡ); (runtime_notifyListAdd, runtime_notifyListAddⁱᵐᵖˡ); (runtime_notifyListWait, runtime_notifyListWaitⁱᵐᵖˡ); (runtime_notifyListNotifyAll, runtime_notifyListNotifyAllⁱᵐᵖˡ); (runtime_notifyListNotifyOne, runtime_notifyListNotifyOneⁱᵐᵖˡ); (runtime_notifyListCheck, runtime_notifyListCheckⁱᵐᵖˡ); (throw, throwⁱᵐᵖˡ); (fatal, fatalⁱᵐᵖˡ); (syscall_hasWaitingReaders, syscall_hasWaitingReadersⁱᵐᵖˡ)].

Axiom copyChecker__checkⁱᵐᵖˡ : val.

Axiom noCopy__Lockⁱᵐᵖˡ : val.

Axiom noCopy__Unlockⁱᵐᵖˡ : val.

Axiom Map__Clearⁱᵐᵖˡ : val.

Axiom Map__CompareAndDeleteⁱᵐᵖˡ : val.

Axiom Map__CompareAndSwapⁱᵐᵖˡ : val.

Axiom Map__Deleteⁱᵐᵖˡ : val.

Axiom Map__Loadⁱᵐᵖˡ : val.

Axiom Map__LoadAndDeleteⁱᵐᵖˡ : val.

Axiom Map__LoadOrStoreⁱᵐᵖˡ : val.

Axiom Map__Rangeⁱᵐᵖˡ : val.

Axiom Map__Storeⁱᵐᵖˡ : val.

Axiom Map__Swapⁱᵐᵖˡ : val.

Axiom Map__dirtyLockedⁱᵐᵖˡ : val.

Axiom Map__loadReadOnlyⁱᵐᵖˡ : val.

Axiom Map__missLockedⁱᵐᵖˡ : val.

Axiom entry__deleteⁱᵐᵖˡ : val.

Axiom entry__loadⁱᵐᵖˡ : val.

Axiom entry__swapLockedⁱᵐᵖˡ : val.

Axiom entry__tryCompareAndSwapⁱᵐᵖˡ : val.

Axiom entry__tryExpungeLockedⁱᵐᵖˡ : val.

Axiom entry__tryLoadOrStoreⁱᵐᵖˡ : val.

Axiom entry__trySwapⁱᵐᵖˡ : val.

Axiom entry__unexpungeLockedⁱᵐᵖˡ : val.

Axiom Pool__Getⁱᵐᵖˡ : val.

Axiom Pool__Putⁱᵐᵖˡ : val.

Axiom Pool__getSlowⁱᵐᵖˡ : val.

Axiom Pool__pinⁱᵐᵖˡ : val.

Axiom Pool__pinSlowⁱᵐᵖˡ : val.

Axiom poolDequeue__packⁱᵐᵖˡ : val.

Axiom poolDequeue__popHeadⁱᵐᵖˡ : val.

Axiom poolDequeue__popTailⁱᵐᵖˡ : val.

Axiom poolDequeue__pushHeadⁱᵐᵖˡ : val.

Axiom poolDequeue__unpackⁱᵐᵖˡ : val.

Axiom poolChain__popHeadⁱᵐᵖˡ : val.

Axiom poolChain__popTailⁱᵐᵖˡ : val.

Axiom poolChain__pushHeadⁱᵐᵖˡ : val.

Axiom poolChainElt__packⁱᵐᵖˡ : val.

Axiom poolChainElt__popHeadⁱᵐᵖˡ : val.

Axiom poolChainElt__popTailⁱᵐᵖˡ : val.

Axiom poolChainElt__pushHeadⁱᵐᵖˡ : val.

Axiom poolChainElt__unpackⁱᵐᵖˡ : val.

Axiom rlocker__Lockⁱᵐᵖˡ : val.

Axiom rlocker__Unlockⁱᵐᵖˡ : val.

Definition msets' : list (go_string * (list (go_string * val))) := [(Cond.id, []); (ptrT.id Cond.id, [("Broadcast"%go, Cond__Broadcastⁱᵐᵖˡ); ("Signal"%go, Cond__Signalⁱᵐᵖˡ); ("Wait"%go, Cond__Waitⁱᵐᵖˡ)]); (copyChecker.id, []); (ptrT.id copyChecker.id, [("check"%go, copyChecker__checkⁱᵐᵖˡ)]); (noCopy.id, []); (ptrT.id noCopy.id, [("Lock"%go, noCopy__Lockⁱᵐᵖˡ); ("Unlock"%go, noCopy__Unlockⁱᵐᵖˡ)]); (Map.id, []); (ptrT.id Map.id, [("Clear"%go, Map__Clearⁱᵐᵖˡ); ("CompareAndDelete"%go, Map__CompareAndDeleteⁱᵐᵖˡ); ("CompareAndSwap"%go, Map__CompareAndSwapⁱᵐᵖˡ); ("Delete"%go, Map__Deleteⁱᵐᵖˡ); ("Load"%go, Map__Loadⁱᵐᵖˡ); ("LoadAndDelete"%go, Map__LoadAndDeleteⁱᵐᵖˡ); ("LoadOrStore"%go, Map__LoadOrStoreⁱᵐᵖˡ); ("Range"%go, Map__Rangeⁱᵐᵖˡ); ("Store"%go, Map__Storeⁱᵐᵖˡ); ("Swap"%go, Map__Swapⁱᵐᵖˡ); ("dirtyLocked"%go, Map__dirtyLockedⁱᵐᵖˡ); ("loadReadOnly"%go, Map__loadReadOnlyⁱᵐᵖˡ); ("missLocked"%go, Map__missLockedⁱᵐᵖˡ)]); (readOnly.id, []); (ptrT.id readOnly.id, []); (entry.id, []); (ptrT.id entry.id, [("delete"%go, entry__deleteⁱᵐᵖˡ); ("load"%go, entry__loadⁱᵐᵖˡ); ("swapLocked"%go, entry__swapLockedⁱᵐᵖˡ); ("tryCompareAndSwap"%go, entry__tryCompareAndSwapⁱᵐᵖˡ); ("tryExpungeLocked"%go, entry__tryExpungeLockedⁱᵐᵖˡ); ("tryLoadOrStore"%go, entry__tryLoadOrStoreⁱᵐᵖˡ); ("trySwap"%go, entry__trySwapⁱᵐᵖˡ); ("unexpungeLocked"%go, entry__unexpungeLockedⁱᵐᵖˡ)]); (Mutex.id, []); (ptrT.id Mutex.id, [("Lock"%go, Mutex__Lockⁱᵐᵖˡ); ("TryLock"%go, Mutex__TryLockⁱᵐᵖˡ); ("Unlock"%go, Mutex__Unlockⁱᵐᵖˡ)]); (Once.id, []); (ptrT.id Once.id, [("Do"%go, Once__Doⁱᵐᵖˡ); ("doSlow"%go, Once__doSlowⁱᵐᵖˡ)]); (Pool.id, []); (ptrT.id Pool.id, [("Get"%go, Pool__Getⁱᵐᵖˡ); ("Put"%go, Pool__Putⁱᵐᵖˡ); ("getSlow"%go, Pool__getSlowⁱᵐᵖˡ); ("pin"%go, Pool__pinⁱᵐᵖˡ); ("pinSlow"%go, Pool__pinSlowⁱᵐᵖˡ)]); (poolLocalInternal.id, []); (ptrT.id poolLocalInternal.id, []); (poolLocal.id, []); (ptrT.id poolLocal.id, []); (poolDequeue.id, []); (ptrT.id poolDequeue.id, [("pack"%go, poolDequeue__packⁱᵐᵖˡ); ("popHead"%go, poolDequeue__popHeadⁱᵐᵖˡ); ("popTail"%go, poolDequeue__popTailⁱᵐᵖˡ); ("pushHead"%go, poolDequeue__pushHeadⁱᵐᵖˡ); ("unpack"%go, poolDequeue__unpackⁱᵐᵖˡ)]); (eface.id, []); (ptrT.id eface.id, []); (dequeueNil.id, []); (ptrT.id dequeueNil.id, []); (poolChain.id, []); (ptrT.id poolChain.id, [("popHead"%go, poolChain__popHeadⁱᵐᵖˡ); ("popTail"%go, poolChain__popTailⁱᵐᵖˡ); ("pushHead"%go, poolChain__pushHeadⁱᵐᵖˡ)]); (poolChainElt.id, []); (ptrT.id poolChainElt.id, [("pack"%go, poolChainElt__packⁱᵐᵖˡ); ("popHead"%go, poolChainElt__popHeadⁱᵐᵖˡ); ("popTail"%go, poolChainElt__popTailⁱᵐᵖˡ); ("pushHead"%go, poolChainElt__pushHeadⁱᵐᵖˡ); ("unpack"%go, poolChainElt__unpackⁱᵐᵖˡ)]); (notifyList.id, []); (ptrT.id notifyList.id, []); (RWMutex.id, []); (ptrT.id RWMutex.id, [("Lock"%go, RWMutex__Lockⁱᵐᵖˡ); ("RLock"%go, RWMutex__RLockⁱᵐᵖˡ); ("RLocker"%go, RWMutex__RLockerⁱᵐᵖˡ); ("RUnlock"%go, RWMutex__RUnlockⁱᵐᵖˡ); ("TryLock"%go, RWMutex__TryLockⁱᵐᵖˡ); ("TryRLock"%go, RWMutex__TryRLockⁱᵐᵖˡ); ("Unlock"%go, RWMutex__Unlockⁱᵐᵖˡ); ("rUnlockSlow"%go, RWMutex__rUnlockSlowⁱᵐᵖˡ)]); (rlocker.id, []); (ptrT.id rlocker.id, [("Lock"%go, rlocker__Lockⁱᵐᵖˡ); ("Unlock"%go, rlocker__Unlockⁱᵐᵖˡ)]); (WaitGroup.id, []); (ptrT.id WaitGroup.id, [("Add"%go, WaitGroup__Addⁱᵐᵖˡ); ("Done"%go, WaitGroup__Doneⁱᵐᵖˡ); ("Wait"%go, WaitGroup__Waitⁱᵐᵖˡ)])].

#[global] Instance info' : PkgInfo sync.sync :=
  {|
    pkg_vars := vars';
    pkg_functions := functions';
    pkg_msets := msets';
    pkg_imported_pkgs := [code.sync.atomic.atomic; code.internal.race.race];
  |}.

Axiom _'init : val.

Definition initialize' : val :=
  λ: <>,
    package.init #sync.sync (λ: <>,
      exception_do (do:  (race.initialize' #());;;
      do:  (atomic.initialize' #());;;
      do:  (package.alloc sync.sync #());;;
      do:  (expunged'init #()))
      ).

End code.
End sync.
